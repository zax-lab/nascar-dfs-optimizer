---
phase: 02-ontology-compiled-constraints-calibration-harness
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/backend/app/constraints/__init__.py
  - apps/backend/app/constraints/compiler.py
  - apps/backend/app/constraints/models.py
  - apps/backend/app/constraints/versioning.py
  - apps/backend/app/tests/test_constraints.py
autonomous: true

must_haves:
  truths:
    - "ConstraintSpec compiles from Neo4j once per slate into immutable in-memory artifact"
    - "Compiled constraints replace live Neo4j queries in simulation/optimization loops"
    - "ConstraintSpec versioning enables reproducible sim/opt runs"
    - "Batch query execution minimizes database round trips (<100ms per slate)"
    - "Driver and track constraints are validated after compilation"
  artifacts:
    - path: "apps/backend/app/constraints/compiler.py"
      provides: "Neo4j batch query compilation with RoutingControl.READ"
      exports: ["compile_constraints_from_neo4j", "ConstraintCompiler"]
      min_lines: 100
    - path: "apps/backend/app/constraints/models.py"
      provides: "Immutable constraint spec dataclasses (frozen=True)"
      exports: ["ConstraintSpec", "DriverConstraints", "TrackConstraints"]
      min_lines: 80
    - path: "apps/backend/app/constraints/versioning.py"
      provides: "Run config versioning for reproducibility"
      exports: ["RunConfig", "version_from_constraints"]
      min_lines: 60
    - path: "apps/backend/app/tests/test_constraints.py"
      provides: "Property-based tests for constraint invariants"
      exports: ["test_constraint_immutability", "test_batch_query_performance"]
      min_lines: 80
  key_links:
    - from: "apps/backend/app/constraints/compiler.py"
      to: "apps/backend/app/ontology.py"
      via: "OntologyDriver._driver for Neo4j connection"
      pattern: "OntologyDriver\\.get_driver\\(\\)"
    - from: "apps/backend/app/constraints/models.py"
      to: "packages/axiomatic-sim/src/axiomatic_sim/ontology_constraints.py"
      via: "Compiled specs replace live Neo4j queries"
      pattern: "ConstraintSpec\\.get_driver_constraints"
    - from: "apps/backend/app/constraints/versioning.py"
      to: "apps/backend/app/constraints/compiler.py"
      via: "RunConfig embeds ConstraintSpec version hash"
      pattern: "RunConfig\\(constraint_spec_hash=.*\\)"
---

<objective>
Compile reproducible constraint specifications from Neo4j into immutable in-memory artifacts to eliminate hidden nondeterminism from live database queries in simulation/optimization inner loops.

Purpose: Live Neo4j queries in hot loops introduce nondeterminism (query timing, connection state) that breaks reproducibility. Compiling constraints once per slate into immutable artifacts ensures deterministic execution and enables version-controlled reproducible runs.

Output: `ConstraintCompiler` that batch-queries Neo4j using `execute_query` with `RoutingControl.READ`, returns frozen `ConstraintSpec` dataclass with driver/track constraints, and `RunConfig` versioning system for reproducibility.
</objective>

<execution_context>
@/Users/zax/.claude/get-shit-done/workflows/execute-plan.md
@/Users/zax/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-ontology-compiled-constraints-calibration-harness/02-RESEARCH.md

@apps/backend/app/ontology.py
@packages/axiomatic-sim/src/axiomatic_sim/ontology_constraints.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create immutable constraint spec models</name>
  <files>apps/backend/app/constraints/models.py</files>
  <action>
    Create frozen dataclasses for constraint specifications in `apps/backend/app/constraints/models.py`:

    1. Import dataclasses and typing:
       ```python
       from dataclasses import dataclass
       from typing import Dict, List, Optional
       ```

    2. Create `DriverConstraints` (frozen=True):
       - Fields: driver_id (str), skill (float), aggression (float), shadow_risk (float), min_laps_led (int), max_laps_led (int), veto_rules (List[str])
       - Add validation: skill/aggression/shadow_risk in [0, 1], min_laps_led <= max_laps_led
       - Add `__post_init__` for validation with ValueError on invalid inputs

    3. Create `TrackConstraints` (frozen=True):
       - Fields: track_id (str), difficulty (float), aggression_factor (float), caution_rate (float), pit_window_laps (List[int])
       - Add validation: difficulty/aggression_factor/caution_rate in [0, 1]
       - Add `__post_init__` for validation

    4. Create `ConstraintSpec` (frozen=True):
       - Fields: slate_id (str), compiled_at (str), drivers (Dict[str, DriverConstraints]), tracks (Dict[str, TrackConstraints]), version (str), hash (str)
       - Add method `get_driver_constraints(driver_id: str) -> DriverConstraints` with error handling
       - Add method `get_track_constraints(track_id: str) -> TrackConstraints` with error handling
       - Compute hash from driver/track constraints in `__post_init__` using hashlib.sha256

    5. Ensure immutability: all dataclasses use `frozen=True`, no mutable defaults

    DO NOT: Use regular classes, skip validation, or allow mutation after creation
  </action>
  <verify>
    ```bash
    cd /Users/zax/Desktop/nascar-model\ copy\ 2/apps/backend && python -c "
    from app.constraints.models import ConstraintSpec, DriverConstraints, TrackConstraints
    import inspect

    # Verify frozen
    assert DriverConstraints.__dataclass_fields__['driver_id'].frozen is True or DriverConstraints.__dataclass_params__.frozen is True

    # Verify validation
    try:
        DriverConstraints(driver_id='test', skill=1.5, aggression=0.5, shadow_risk=0.5, min_laps_led=0, max_laps_led=100, veto_rules=[])
        print('FAIL: validation not enforced')
    except ValueError:
        print('PASS: validation enforced')

    # Verify hash computation
    print('Methods:', [m for m in dir(ConstraintSpec) if not m.startswith('_')])
    "
    ```
  </verify>
  <done>
    Frozen dataclasses created with validation preventing invalid constraint values. Hash computed from constraints for versioning.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement Neo4j batch query compiler</name>
  <files>apps/backend/app/constraints/compiler.py</files>
  <action>
    Implement `ConstraintCompiler` in `apps/backend/app/constraints/compiler.py` using Neo4j batch queries:

    1. Import dependencies:
       ```python
       from neo4j import GraphDatabase, RoutingControl
       from datetime import datetime
       from typing import List, Dict
       import logging
       from app.constraints.models import ConstraintSpec, DriverConstraints, TrackConstraints
       from app.ontology import OntologyDriver
       ```

    2. Create `ConstraintCompiler` class:
       - `__init__(self, ontology_driver: OntologyDriver)`: store driver reference
       - `compile_driver_constraints(self, driver_ids: List[str]) -> Dict[str, DriverConstraints]`:
         * Use `driver._driver.execute_query()` with batch Cypher query
         * Query: `MATCH (d:Driver) WHERE d.driver_id IN $driver_ids RETURN d.driver_id, d.skill, d.psyche_aggression, d.shadow_risk`
         * Use `routing_=RoutingControl.READ` for efficient reads
         * Build dict mapping driver_id -> DriverConstraints
         * Add derived min_laps_led=0, max_laps_led from track length (placeholder 100)
         * Add veto_rules from VETO_RULE relationships (OPTIONAL MATCH)
       - `compile_track_constraints(self, track_ids: List[str]) -> Dict[str, TrackConstraints]`:
         * Use batch query for tracks: `MATCH (t:Track) WHERE t.track_id IN $track_ids RETURN t.track_id, t.difficulty, t.aggression_factor`
         * Build dict mapping track_id -> TrackConstraints
         * Add caution_rate=0.05, pit_window_laps=[35, 70, 105, 140, 175] (standard windows)
       - `compile_spec(self, slate_id: str, driver_ids: List[str], track_ids: List[str]) -> ConstraintSpec`:
         * Call compile_driver_constraints and compile_track_constraints
         * Compute version hash from constraints
         * Return frozen ConstraintSpec with compiled_at timestamp

    3. Add error handling and logging:
       - Log compilation start/end with timing
       - Handle Neo4j query errors with detailed error messages
       - Validate that all requested drivers/tracks were found

    4. Ensure batch queries: all drivers fetched in single query, all tracks in single query

    DO NOT: Use individual queries per driver/track, skip logging, or allow partial compilation
  </action>
  <verify>
    ```bash
    cd /Users/zax/Desktop/nascar-model\ copy\ 2/apps/backend && python -c "
    from app.ontology import OntologyDriver, DriverNode, TrackNode
    from app.constraints.compiler import ConstraintCompiler
    import time

    # Mock: create test driver and track nodes
    # (In real execution, Neo4j must be running)

    # Test batch query performance
    compiler = ConstraintCompiler(ontology_driver)
    start = time.time()
    spec = compiler.compile_spec('test_slate', ['driver_1', 'driver_2'], ['track_1'])
    duration = time.time() - start

    assert duration < 0.1, f'Batch query too slow: {duration}s'
    assert len(spec.drivers) == 2, 'Not all drivers compiled'
    assert len(spec.tracks) == 1, 'Not all tracks compiled'
    print(f'PASS: Compiled {len(spec.drivers)} drivers in {duration:.3f}s')
    "
    ```
  </verify>
  <done>
    ConstraintCompiler batch-queries Neo4j in <100ms, returns frozen ConstraintSpec with all driver/track constraints validated.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement run config versioning system</name>
  <files>apps/backend/app/constraints/versioning.py</files>
  <action>
    Create run config versioning system in `apps/backend/app/constraints/versioning.py`:

    1. Import dependencies:
       ```python
       from dataclasses import dataclass, asdict
       from typing import Dict, Any, Optional
       from datetime import datetime
       import hashlib
       import json
       from app.constraints.models import ConstraintSpec
       ```

    2. Create `RunConfig` dataclass (frozen=True):
       - Fields: run_id (str), constraint_spec_hash (str), sim_params (Dict[str, Any]), created_at (str), random_seed (int)
       - `sim_params` includes: n_scenarios, field_size, race_length
       - Add validation: random_seed must be positive integer, n_scenarios > 0
       - Add `__post_init__` validation

    3. Create `version_from_constraints(spec: ConstraintSpec) -> str` function:
       - Serialize constraint spec to JSON (use asdict)
       - Sort keys for deterministic serialization
       - Compute SHA-256 hash of JSON string
       - Return hex digest as version string

    4. Create `create_run_config(spec: ConstraintSpec, sim_params: Dict[str, Any], random_seed: int) -> RunConfig` function:
       - Compute constraint_spec_hash using version_from_constraints
       - Generate run_id from timestamp + constraint_spec_hash
       - Return frozen RunConfig

    5. Create `save_run_config(config: RunConfig, path: str)` function:
       - Serialize to JSON with pretty formatting
       - Write to specified path
       - Add logging

    6. Create `load_run_config(path: str) -> RunConfig` function:
       - Load JSON from file
       - Reconstruct RunConfig object
       - Validate constraint_spec_hash format

    DO NOT: Allow mutation of RunConfig, use non-deterministic serialization, or skip hash validation
  </action>
  <verify>
    ```bash
    cd /Users/zax/Desktop/nascar-model\ copy\ 2/apps/backend && python -c "
    from app.constraints.versioning import version_from_constraints, create_run_config, save_run_config, load_run_config
    from app.constraints.models import ConstraintSpec, DriverConstraints, TrackConstraints
    import tempfile
    import os

    # Test versioning determinism
    spec = ConstraintSpec(
        slate_id='test',
        compiled_at='2024-01-01T00:00:00',
        drivers={'d1': DriverConstraints('d1', 0.5, 0.5, 0.5, 0, 100, [])},
        tracks={'t1': TrackConstraints('t1', 0.5, 0.5, 0.05, [35, 70])},
        version='1.0',
        hash='test_hash'
    )

    # Same spec should produce same version hash
    v1 = version_from_constraints(spec)
    v2 = version_from_constraints(spec)
    assert v1 == v2, 'Version hash not deterministic'

    # Test run config round-trip
    config = create_run_config(spec, {'n_scenarios': 100}, 42)
    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:
        path = f.name
    save_run_config(config, path)
    loaded = load_run_config(path)
    assert loaded.run_id == config.run_id, 'Run config round-trip failed'
    os.unlink(path)

    print('PASS: Versioning deterministic, run config round-trip successful')
    "
    ```
  </verify>
  <done>
    RunConfig versioning produces deterministic hashes from ConstraintSpec, enables reproducible runs with saved configs.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Immutability check**: Verify ConstraintSpec, DriverConstraints, TrackConstraints, RunConfig are frozen (cannot set attributes after creation)

2. **Performance check**: Compile constraints for 40 drivers + 1 track in <100ms (single batch query)

3. **Validation check**: Attempt to create DriverConstraints with skill=1.5 raises ValueError

4. **Versioning check**: Same ConstraintSpec produces identical hash across multiple calls

5. **Round-trip check**: RunConfig saved/loaded produces identical object

Test commands:
```bash
cd /Users/zax/Desktop/nascar-model\ copy\ 2/apps/backend
python -m pytest tests/test_constraints.py -v
```
</verification>

<success_criteria>
- ConstraintSpec compiles from Neo4j once per slate into frozen dataclass
- No live Neo4j queries in inner simulation/optimization loops (use compiled spec)
- RunConfig versioning enables reproducible sim/opt runs with saved configs
- Batch query execution completes in <100ms for 40 drivers
- Property-based tests validate constraint invariants (immutability, validation, versioning)
</success_criteria>

<output>
After completion, create `.planning/phases/02-ontology-compiled-constraints-calibration-harness/02-01-SUMMARY.md` with:
- Files created (constraints module with compiler, models, versioning)
- Performance metrics (batch query timing for 40 drivers)
- Test coverage (property-based tests passing)
- Next steps (integrate compiled constraints with SkeletonNarrative)
</output>
