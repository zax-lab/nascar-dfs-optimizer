---
phase: 05-critical-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/backend/pyproject.toml
  - docker-compose.yml
  - apps/backend/app/job_manager.py
autonomous: true

must_haves:
  truths:
    - "Redis server starts successfully and accepts connections"
    - "Backend can connect to Redis using connection pool"
    - "Redis health check completes within 3 seconds"
  artifacts:
    - path: "apps/backend/app/job_manager.py"
      provides: "JobStateManager class with Redis backing"
      min_lines: 150
      exports: ["JobStateManager"]
    - path: "docker-compose.yml"
      provides: "Redis service definition"
      contains: "redis:"
    - path: "apps/backend/pyproject.toml"
      provides: "Redis client dependency"
      contains: "redis"
  key_links:
    - from: "apps/backend/app/main.py"
      to: "redis:6379"
      via: "ConnectionPool in lifespan"
      pattern: "redis\\.ConnectionPool"
    - from: "apps/backend/app/job_manager.py"
      to: "Redis"
      via: "redis.Redis() with connection_pool"
      pattern: "self\\.redis\\.hset|self\\.redis\\.hget|self\\.redis\\.expire"
    - from: "apps/backend/app/main.py"
      to: "app.state.job_manager"
      via: "JobStateManager initialization in lifespan"
      pattern: "app\\.state\\.job_manager\\s*=\\s*JobStateManager"
---

<objective>
Create Redis-based job state persistence to replace in-memory job storage, ensuring jobs survive container restarts.

Purpose: Addresses the highest-priority production blocker where jobs are lost when containers restart. Redis provides durable job state with automatic TTL-based cleanup.

Output: Redis service in docker-compose.yml, JobStateManager class, updated dependencies
</objective>

<execution_context>
@/Users/zax/.claude/get-shit-done/workflows/execute-plan.md
@/Users/zax/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/05-critical-infrastructure/05-CONTEXT.md
@.planning/phases/05-critical-infrastructure/05-RESEARCH.md
@apps/backend/app/api/optimize.py
@docker-compose.yml
@apps/backend/pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Add Redis to infrastructure stack</name>
  <files>docker-compose.yml, apps/backend/pyproject.toml</files>
  <action>
  1. Update docker-compose.yml:
     - Add Redis service after Neo4j section (around line 36)
     - Use image: redis:7-alpine
     - Expose port 6379
     - Add healthcheck with redis-cli ping
     - Add volume for persistence
     - Configure resource limits (256MB memory, 0.5 CPU)
     - Add to nascar-network
  2. Update backend service depends_on to wait for Redis healthy
  3. Add redis-py dependency to pyproject.toml: "redis>=5.0.0"
  4. Add REDIS_HOST and REDIS_PORT environment variables to backend service

  Do NOT add authentication or TLS (Phase 5.2 scope).
  </action>
  <verify>
  docker-compose up redis -d && docker-compose ps redis | grep "healthy"
  </verify>
  <done>
  Redis container starts successfully, healthcheck passes, backend waits for Redis before starting
  </done>
</task>

<task type="auto">
  <name>Create JobStateManager class</name>
  <files>apps/backend/app/job_manager.py</files>
  <action>
  Create apps/backend/app/job_manager.py with:

  1. JobStateManager class with __init__(redis_pool):
     - Store redis.Redis(connection_pool=redis_pool)
     - Parse JOB_TTL_DAYS from os.getenv (default: "7")
     - Calculate TTL as ttl_days * 86400

  2. async def create_job(job_id, input_params, correlation_id):
     - Build job_data dict with: status="pending", input_params (json), result="", error_message="", created_at (isoformat), updated_at (isoformat), scenario_count="0", slate_id, correlation_id
     - Call self.redis.hset(f"job:{job_id}", mapping=job_data)
     - Call self.redis.expire(f"job:{job_id}", self.ttl)

  3. async def get_job(job_id) -> Optional[dict]:
     - Call self.redis.hgetall(f"job:{job_id}")
     - Return None if empty, else decode bytes to strings and return dict

  4. async def update_job_status(job_id, status, result=None, error=None):
     - Build updates dict with status and updated_at (isoformat)
     - If result: updates["result"] = json.dumps(result)
     - If error: updates["error_message"] = json.dumps(error)
     - Call self.redis.hset(f"job:{job_id}", mapping=updates)

  5. async def get_running_job_count() -> int:
     - Use self.redis.scan_iter("job:*") to find all job keys
     - For each key, get status field with hget
     - Count jobs where status == "running"
     - Return count (for graceful shutdown monitoring)

  6. Wire JobStateManager to optimize.py endpoints:
     - In main.py Task 3, after initializing JobStateManager, the integration point is established in app.state.job_manager
     - Plan 05-02 Task 1 will depend on this integration point when migrating optimize.py endpoints to use JobStateManager
     - No additional wiring needed in this plan - optimize.py migration is scope of Plan 05-02

  Use redis-py patterns from RESEARCH.md (ConnectionPool with health_check_interval=30, socket_timeout=3).
  Use json module for serialization, datetime.utcnow().isoformat() for timestamps.
  </action>
  <verify>
  python -c "from app.job_manager import JobStateManager; print(JobStateManager.__doc__)"
  </verify>
  <done>
  JobStateManager class exists with all 5 methods, docstrings present, uses Redis hash operations
  </done>
</task>

<task type="auto">
  <name>Initialize Redis connection pool in FastAPI lifespan</name>
  <files>apps/backend/app/main.py</files>
  <action>
  1. Import redis, contextlib (for asynccontextmanager), JobStateManager
  2. Replace @app.on_event("startup") and @app.on_event("shutdown") with lifespan:
     - Create @asynccontextmanager async def lifespan(app: FastAPI):
     - In startup section:
       * Create redis.ConnectionPool(host=REDIS_HOST, port=REDIS_PORT, db=0, health_check_interval=30, socket_timeout=3, socket_connect_timeout=3, decode_responses=True)
       * Store in app.state.redis_pool
       * Create redis.Redis(connection_pool=app.state.redis_pool)
       * Store in app.state.redis_client
       * Initialize JobStateManager(app.state.redis_pool)
       * Store in app.state.job_manager
       * Log "Redis connected, JobStateManager initialized"
     - Yield
     - In shutdown section:
       * Log "Shutting down Redis connection"
       * Call app.state.redis_client.close()
       * Call app.state.redis_pool.disconnect()
  3. Pass lifespan to FastAPI(): app = FastAPI(..., lifespan=lifespan)

  Do NOT implement graceful shutdown yet (Plan 05-02).
  Keep existing rate limiter and CORS middleware (they work fine).
  </action>
  <verify>
  docker-compose up backend && docker-compose logs backend | grep "Redis connected"
  </verify>
  <done>
  FastAPI starts without errors, logs show "Redis connected", no startup exceptions
  </done>
</task>

</tasks>

<verification>
1. Redis container starts and healthcheck passes
2. Backend connects to Redis successfully (no connection errors in logs)
3. JobStateManager can be imported and instantiated
4. Redis connection pool is stored in app.state.redis_pool
5. JobStateManager is stored in app.state.job_manager
</verification>

<success_criteria>
1. docker-compose up -d starts all services (neo4j, redis, backend) successfully
2. Backend logs show "Redis connected, JobStateManager initialized"
3. Redis container healthcheck shows "healthy" in docker-compose ps
4. curl http://localhost:8000/health returns {"status": "ok", "version": "0.3.0"}
5. No Redis connection errors in backend logs
</success_criteria>

<output>
After completion, create `.planning/phases/05-critical-infrastructure/05-01-SUMMARY.md`
</output>
