---
phase: 06-foundation-gui-local-optimization
plan: 06
type: execute
wave: 3
depends_on: ["06-02", "06-04"]
files_modified:
  - apps/native_mac/optimization/engine.py
  - apps/native_mac/optimization/mcmc_optimizer.py
  - apps/native_mac/optimization/progress_worker.py
autonomous: true

must_haves:
  truths:
    - "User clicks 'Run Optimization' button and optimization executes locally using JAX[cpu]"
    - "Progress bar shows MCMC job progress from 0% to 100% over 30-60 seconds"
    - "Optimization runs on Apple Silicon using native ARM64 JAX builds"
    - "Optimization produces valid 6-driver lineups respecting salary cap constraints"
    - "Generated lineups are saved to database and displayed in Lineups tab"
  artifacts:
    - path: "apps/native_mac/optimization/engine.py"
      provides: "OptimizationEngine class wrapping MCMC optimizer with JAX backend"
      min_lines: 80
    - path: "apps/native_mac/optimization/mcmc_optimizer.py"
      provides: "MCMC lineup optimizer using JAX for local computation"
      contains: "jax"
    - path: "apps/native_mac/optimization/progress_worker.py"
      provides: "QThread worker for running optimization with progress signals"
      contains: "QThread"
  key_links:
    - from: "apps/native_mac/optimization/engine.py"
      to: "apps/native_mac/persistence/database.py"
      via: "DatabaseManager for saving results"
      pattern: "from.*persistence.database import DatabaseManager"
    - from: "apps/native_mac/optimization/progress_worker.py"
      to: "apps/native_mac/optimization/engine.py"
      via: "OptimizationEngine usage"
      pattern: "from.*optimization.engine import OptimizationEngine"
    - from: "apps/native_mac/gui/main_window.py"
      to: "apps/native_mac/optimization/progress_worker.py"
      via: "QThread worker integration"
      pattern: "from.*optimization.progress_worker import OptimizationWorker"
---

## Objective

Implement the local optimization engine using JAX[cpu] for Apple Silicon, with progress indication for MCMC jobs. This is the core computational feature that generates optimized lineups from driver data.

**Purpose:** The optimization is the primary value of the application. It must run locally (for privacy and speed), leverage Apple Silicon for performance, and provide visual feedback during the 30-60 second MCMC sampling process.

**Output:** Working optimization engine that generates lineups with real-time progress updates.

## Context

@/Users/zax/.claude/get-shit-done/workflows/execute-plan.md
@/Users/zax/.claude/get-shit-done/templates/summary.md

@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-foundation-gui-local-optimization/06-RESEARCH.md
@.planning/phases/06-foundation-gui-local-optimization/06-02-SUMMARY.md
@.planning/phases/06-foundation-gui-local-optimization/06-04-SUMMARY.md

@apps/backend/app/optimizer.py
@apps/backend/app/portfolio_generator.py

## Tasks

<task type="auto">
  <name>Create JAX-based MCMC optimizer for local computation</name>
  <files>apps/native_mac/optimization/mcmc_optimizer.py</files>
  <action>
Create MCMC optimizer using JAX for local Apple Silicon computation:

1. Create `apps/native_mac/optimization/` directory with `__init__.py`

2. Create `mcmc_optimizer.py` with MCMCLineupOptimizer class:
   - JAX-based implementation (similar to backend optimizer)
   - Configurable iterations: default 1000, max 5000
   - Temperature parameter for MCMC sampling
   - Salary cap constraint: $50,000 for DraftKings
   - Lineup size: 6 drivers per lineup

3. Implement optimize() method signature:
```python
def optimize(
    self,
    drivers: list[dict],  # {driver_id, name, salary, projected_points}
    num_lineups: int = 20,
    salary_cap: int = 50000,
    iterations: int = 1000,
    constraints: dict = None,  # {min_salary, max_exposure, stacking_rules}
    progress_callback: callable = None  # Called with (current, total, best_score)
) -> list[dict]:
```

4. JAX implementation requirements:
   - Use jax.numpy for array operations
   - JAX random key for reproducibility
   - Vectorized operations for performance
   - Support both CPU (default) and Metal GPU (optional)

5. Progress callback integration:
   - Call progress_callback(iteration, total_iterations, current_best_score)
   - Callback frequency: every 10 iterations (not every iteration for performance)

6. Reference existing backend optimizer but adapt for:
   - Local execution (no API calls)
   - Desktop memory constraints
   - Progress reporting
   - Cancellation support (check flag between iterations)

Follow research pattern from 06-RESEARCH.md > JAX Local Optimization.
  </action>
  <verify>
MCMLineupOptimizer class exists with optimize method
Method accepts drivers list and returns list of lineup dicts
JAX is imported and used for array operations
Salary cap constraint enforced in generated lineups
Progress callback called during optimization
Iterations parameter controls MCMC sampling length
  </verify>
  <done>
JAX-based MCMC optimizer created
Local computation working on Apple Silicon
Progress reporting integrated
Salary cap and lineup size constraints enforced
  </done>
</task>

<task type="auto">
  <name>Create QThread worker for optimization with progress signals</name>
  <files>apps/native_mac/optimization/progress_worker.py</files>
  <action>
Create QThread worker to run optimization without blocking UI:

1. Create `progress_worker.py` with OptimizationWorker class:
   - Subclass QThread
   - Signals: progress(int, int, float), finished(list), error(str), cancelled()

2. Implement signal definitions:
```python
class OptimizationWorker(QThread):
    progress = Signal(int, int, float)  # current, total, best_score
    finished = Signal(list)  # list of lineup dicts
    error = Signal(str)  # error message
    cancelled = Signal()  # user cancelled
```

3. Constructor accepts:
   - optimizer: MCMCLineupOptimizer instance
   - drivers: list of driver dicts
   - num_lineups: int
   - constraints: dict

4. Implement run() method:
   - Wrap optimizer.optimize() call
   - Catch exceptions and emit error signal
   - Check cancellation flag between iterations
   - Emit finished signal with results

5. Implement cancel() method:
   - Sets internal _cancelled flag to True
   - Optimizer checks flag and raises CancellationError

6. Progress relay:
   - Connect optimizer's progress_callback to progress signal
   - Ensure thread-safe signal emission

Follow research pattern from 06-RESEARCH.md > QThread Worker Pattern.
  </action>
  <verify>
OptimizationWorker subclasses QThread
Signals defined: progress, finished, error, cancelled
run() method calls optimizer.optimize() in try/except
Cancel mechanism implemented with flag
Progress callback connected to progress signal
Thread-safe signal emission used
  </verify>
  <done>
QThread worker created for non-blocking optimization
Progress signals emit during MCMC iterations
Cancellation mechanism working
Error handling captures optimizer exceptions
  </done>
</task>

<task type="auto">
  <name>Create OptimizationEngine wrapper with database integration</name>
  <files>apps/native_mac/optimization/engine.py</files>
  <action>
Create OptimizationEngine facade that coordinates optimizer, worker, and persistence:

1. Create `engine.py` with OptimizationEngine class:
   - High-level API for GUI to use
   - Manages optimizer lifecycle
   - Handles database persistence of results
   - Provides configuration management

2. Constructor accepts:
   - database_manager: DatabaseManager instance
   - default_iterations: int = 1000
   - default_num_lineups: int = 20

3. Implement methods:
```python
def start_optimization(
    self,
    race_id: int,
    drivers: list[dict],
    constraints: dict = None,
    progress_callback: callable = None,
    finished_callback: callable = None
) -> OptimizationWorker:
    """Start optimization in background thread, return worker for monitoring."""

def save_results(self, race_id: int, lineups: list[dict]) -> list[int]:
    """Save generated lineups to database, return lineup IDs."""

def load_results(self, race_id: int) -> list[dict]:
    """Load previously generated lineups for a race."""
```

4. start_optimization implementation:
   - Create MCMCLineupOptimizer instance
   - Create OptimizationWorker with optimizer
   - Connect worker signals to callbacks
   - Start worker with QThread
   - Return worker reference for cancellation

5. save_results implementation:
   - Validate lineup format (6 drivers, salary within cap)
   - Insert into database via DatabaseManager
   - Return list of lineup IDs for reference

6. Configuration management:
   - Load default constraints from app_state
   - Save user preferences (iterations, num_lineups)

Follow research pattern from 06-RESEARCH.md > Optimization Engine Facade.
  </action>
  <verify>
OptimizationEngine class exists with start_optimization method
Method accepts race_id, drivers, constraints, callbacks
Returns OptimizationWorker instance
save_results validates lineup format before saving
Database integration via DatabaseManager
Configuration loaded from app_state
  </verify>
  <done>
OptimizationEngine facade created
Database persistence integrated
Configuration management working
High-level API ready for GUI integration
  </done>
</task>

## Verification

After completing all tasks, verify the optimization engine:

1. Run test script to verify JAX installation:
```python
import jax
print(jax.devices())  # Should show CPU (or Metal GPU if available)
```

2. Test optimizer with sample driver data:
```python
from apps.native_mac.optimization.mcmc_optimizer import MCMCLineupOptimizer
optimizer = MCMCLineupOptimizer()
drivers = [...]  # Sample data
results = optimizer.optimize(drivers, num_lineups=5, iterations=100)
assert len(results) == 5
assert all(len(r['drivers']) == 6 for r in results)
assert all(r['total_salary'] <= 50000 for r in results)
```

3. Test progress worker:
```python
from apps.native_mac.optimization.progress_worker import OptimizationWorker
worker = OptimizationWorker(optimizer, drivers, num_lineups=5)
worker.progress.connect(lambda c, t, s: print(f"{c}/{t}: {s}"))
worker.start()
worker.wait()
```

4. Verify progress updates during optimization
5. Test cancellation mechanism

## Success Criteria

- [ ] JAX optimizer generates valid 6-driver lineups
- [ ] Salary cap constraint ($50,000) enforced
- [ ] Progress callback called during MCMC iterations
- [ ] QThread worker runs optimization without blocking UI
- [ ] Cancellation mechanism stops optimization cleanly
- [ ] Results saved to database with proper lineup IDs
- [ ] JAX uses Apple Silicon ARM64 builds (check with `jax.devices()`)

## Output

After completion, create `.planning/phases/06-foundation-gui-local-optimization/06-06-SUMMARY.md`
