---
phase: 01-feasible-by-design-nascar-simulation-core
plan: 03
type: execute
wave: 3
depends_on: ["01-01", "01-02", "01-04"]
files_modified:
  - packages/axiomatic-sim/src/scenario_generator.py
  - packages/axiomatic-sim/src/narrative.py
  - packages/axiomatic-sim/tests/test_scenario_generator.py
autonomous: true

must_haves:
  truths:
    - "Skeleton Narrative generator produces 1,000+ coherent scenarios per slate with realistic race-flow regimes"
    - "Each scenario includes component distributions (laps led, fastest laps, finish position, place differential, incidents)"
    - "Scenarios respect conservation constraints (laps led ≤ race length, fastest laps ≤ green flag laps)"
    - "Race-flow regimes vary (caution count, pit strategy patterns) to capture uncertainty"
    - "Kernel validates all scenarios pass conservation checks (post-generation validation)"
  artifacts:
    - path: "packages/axiomatic-sim/src/scenario_generator.py"
      provides: "Skeleton Narrative scenario generator using CBN sampling"
      min_lines: 280
      exports: ["SkeletonNarrative", "ScenarioGenerator", "generate_scenarios", "Scenario"]
    - path: "packages/axiomatic-sim/src/narrative.py"
      provides: "Race-flow regime modeling and scenario data structures"
      min_lines: 150
      exports: ["RaceFlowRegime", "ScenarioComponents", "serialize_scenario", "deserialize_scenario"]
    - path: "packages/axiomatic-sim/tests/test_scenario_generator.py"
      provides: "Integration tests for scenario generation pipeline"
      min_lines: 140
  key_links:
    - from: "packages/axiomatic-sim/src/scenario_generator.py"
      to: "packages/axiomatic-sim/src/cbn.py"
      via: "Use CausalBayesianNetwork.sample_outcomes to sample conditional driver outcomes"
      pattern: "cbn\.sample_outcomes\(.*evidence="
    - from: "packages/axiomatic-sim/src/scenario_generator.py"
      to: "packages/axiomatic-sim/src/state_space.py"
      via: "Use RaceState and transitions for lap-by-lap simulation"
      pattern: "from.*state_space.*import.*RaceState"
    - from: "packages/axiomatic-sim/src/narrative.py"
      to: "packages/axiomatic-sim/src/scenario_generator.py"
      via: "Import ScenarioComponents for scenario data structure"
      pattern: "from.*narrative.*import.*ScenarioComponents"
    - from: "packages/axiomatic-sim/src/scenario_generator.py"
      to: "apps/backend/app/kernel.py"
      via: "Call kernel.validate_dominator_conservation to post-validate all generated scenarios"
      pattern: "kernel\.validate_dominator_conservation\("
---

<objective>
Build Skeleton Narrative scenario generator that produces 1,000+ mechanically plausible race outcomes per slate using CBN sampling and state space simulation.

Purpose: This is the core simulation engine that generates diverse race outcomes (dominator races, chaos races, fuel-mileage races) while respecting conservation constraints. Scenarios feed downstream into tail metrics and optimization.

Output: Scenario generator with race-flow regime modeling, CBN-conditioned outcome sampling, serialization support, integration tests
</objective>

<execution_context>
@/Users/zax/.claude/get-shit-done/workflows/execute-plan.md
@/Users/zax/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-feasible-by-design-nascar-simulation-core/01-CONTEXT.md
@.planning/phases/01-feasible-by-design-nascar-simulation-core/01-RESEARCH.md
@.planning/phases/01-feasible-by-design-nascar-simulation-core/01-01-PLAN.md
@.planning/phases/01-feasible-by-design-nascar-simulation-core/01-02-PLAN.md

# Research decisions applied from 01-RESEARCH.md:
- Scenario count: 1,000 as minimum viable
- Hybrid granularity: Event-driven for key segments (caution, pit cycle, late race)
- Conservation enforcement: Feasible-by-design for strict constraints (laps led via Dirichlet)
- Serialization: Parquet format with PyArrow for efficient I/O
</context>

<tasks>

<task type="auto">
  <name>Define Skeleton Narrative data structures and race-flow regime types</name>
  <files>packages/axiomatic-sim/src/narrative.py</files>
  <action>
    Create `packages/axiomatic-sim/src/narrative.py` with:

    1. **RaceFlowRegime dataclass**:
       - `n_cautions: int` (number of caution periods, 0-10)
       - `pit_strategy: PitStrategy` (enum: AGGRESSIVE, STANDARD, CONSERVATIVE)
       - `fuel_window_risk: float` (0-1, probability of fuel mileage race)
       - `late_race_chaos: float` (0-1, probability of late-race incidents)

    2. **PitStrategy enum**:
       - AGGRESSIVE (early pit stops, prioritize track position)
       - STANDARD (pit around median lap window)
       - CONSERVATIVE (late pit stops, prioritize fuel tires)

    3. **ScenarioComponents dataclass**:
       - `scenario_id: str` (UUID or hash)
       - `regime: RaceFlowRegime` (race-flow regime for this scenario)
       - `driver_outcomes: Dict[str, DriverOutcome]` (driver_id -> outcome)
       - `conservation_metadata: ConservationMetadata` (validation info)

    4. **DriverOutcome dataclass**:
       - `driver_id: str`
       - `laps_led: int` (0-race_length)
       - `fastest_laps: int` (0-green_flag_laps)
       - `finish_position: int` (1-field_size, 40 for DNF)
       - `place_differential: int` (finish - starting_position, negative = gained positions)
       - `incident: bool` (True if DNF or involved in incident)
       - `dnf_lap: Optional[int]` (lap of DNF, None if finished)

    5. **ConservationMetadata dataclass**:
       - `total_laps_led: int` (sum of all driver laps_led, must ≤ race_length)
       - `total_fastest_laps: int` (sum of all driver fastest_laps, must ≤ green_flag_laps)
       - `green_flag_laps: int` (race_length - caution_laps)
       - `validation_passed: bool` (True if conservation holds)
       - `veto_reasons: List[str]` (empty if valid, populated if violations)

    6. **Serialization functions**:
       - `def serialize_scenario(scenario: ScenarioComponents) -> dict`:
         - Convert to JSON-serializable dict
         - Use dataclasses.asdict for nested dataclasses
         - Return dict with primitive types only

       - `def deserialize_scenario(data: dict) -> ScenarioComponents`:
         - Reconstruct ScenarioComponents from dict
         - Validate all fields present and valid
         - Raise ValueError if invalid

       - `def serialize_scenarios_to_parquet(scenarios: List[ScenarioComponents], path: str)`:
         - Convert list to pandas DataFrame
         - Use pyarrow.parquet.write_table for efficient storage
         - Include scenario_id, regime components, driver outcomes as nested columns

       - `def deserialize_scenarios_from_parquet(path: str) -> List[ScenarioComponents]`:
         - Read parquet file with pyarrow.parquet.read_table
         - Convert to list of ScenarioComponents
         - Validate each scenario during reconstruction

    Import required modules:
    - `from dataclasses import dataclass, asdict`
    - `from typing import Dict, List, Optional`
    - `from enum import Enum`
    - `import uuid`
    - `import pyarrow.parquet as pq`
    - `import pandas as pd`

    DO NOT: Implement scenario generation logic (that's in scenario_generator.py). DO NOT: Define CBN or state space types (import from respective modules).
  </action>
  <verify>
    Run `python -c "from packages.axiomatic_sim.src.narrative import RaceFlowRegime, ScenarioComponents, serialize_scenario; print('Narrative module imports successfully')"`
  </verify>
  <done>
    RaceFlowRegime and ScenarioComponents dataclasses defined with all fields, PitStrategy enum has 3 values, serialization functions convert to/from dict and parquet
  </done>
</task>

<task type="auto">
  <name>Create mock CBN with fixed priors for scenario generation</name>
  <files>packages/axiomatic-sim/src/scenario_generator.py</files>
  <action>
    Add to `packages/axiomatic-sim/src/scenario_generator.py`:

    1. **create_mock_cbn function**:
       - Signature: `def create_mock_cbn(ontology_constraints: OntologyConstraints, driver_ids: List[str]) -> CausalBayesianNetwork`
       - Create fixed CBN structure with hardcoded edges:
         - skill → laps_led
         - skill → fastest_laps
         - aggression → incidents
         - track_difficulty → finish_position
       - Set fixed priors from ontology_constraints:
         - For each driver: skill, aggression from get_driver_priors()
       - Create fixed CPDs (Conditional Probability Distributions):
         - P(laps_led | skill) = Laplace(p=skill, scale=0.1)
         - P(fastest_laps | skill) = Laplace(p=skill*0.3, scale=0.05)
         - P(incidents | aggression) = Bernoulli(p=aggression*0.1)
         - P(finish_position | track_difficulty) = Categorical(p=softmax(skill))
       - Return CausalBayesianNetwork instance

    Import from prior plans:
    - `from packages.axiomatic_sim.src.cbn import CausalBayesianNetwork, create_cbn_variables`
    - `from packages.axiomatic_sim.src.ontology_constraints import OntologyConstraints`
    - `from typing import List, Dict`

    DO NOT: Learn structure from data (that's for Phase 2). DO NOT: Implement scenario generation logic (that's in SkeletonNarrative class).
  </action>
  <verify>
    Run `python -c "from packages.axiomatic_sim.src.scenario_generator import create_mock_cbn; print('Mock CBN creation function exists')"`
  </verify>
  <done>
    create_mock_cbn function creates CausalBayesianNetwork with fixed structure and priors, hardcoded edges reflect domain knowledge, fixed CPDs use driver skill from ontology
  </done>
</task>

<task type="auto">
  <name>Implement Skeleton Narrative scenario generator with CBN-conditioned sampling</name>
  <files>packages/axiomatic-sim/src/scenario_generator.py</files>
  <action>
    Create `packages/axiomatic-sim/src/scenario_generator.py` with:

    1. **SkeletonNarrative class**:
       - `__init__(self, cbn: CausalBayesianNetwork, ontology_constraints: OntologyConstraints, track_id: str, field_size: int = 40, kernel: Optional[KernelLogic] = None)`:
         - Store CBN, ontology constraints, track_id, field_size, kernel
         - Fetch track difficulty from ontology
         - Initialize random seed for reproducibility

       - `sample_race_flow_regime(self) -> RaceFlowRegime`:
         - Sample n_cautions from Poisson distribution (lambda=3 for intermediate tracks)
         - Sample pit_strategy from categorical distribution (P=0.3 aggressive, 0.5 standard, 0.2 conservative)
         - Sample fuel_window_risk and late_race_chaos from Beta distributions (track-specific)
         - Return RaceFlowRegime

       - `generate_single_scenario(self, scenario_id: str) -> ScenarioComponents`:
         - Sample race_flow_regime
         - Initialize RaceState from state_space module
         - Simulate race using transitions:
           - For each caution: apply caution_transition
           - For pit cycle: apply pit_cycle_transition with sampled pitting drivers
           - For green flag runs: apply green_flag_transition
         - At final lap: extract driver outcomes from RaceState
         - NOTE: Do NOT validate conservation internally - kernel post-validation handles this
         - Return ScenarioComponents (conservation_metadata will be populated by kernel)

       - `generate_scenarios(self, n_scenarios: int = 1000) -> List[ScenarioComponents]`:
         - Generate n_scenarios in parallel using multiprocessing or JAX vmap
         - Filter out scenarios that fail kernel conservation validation
         - Re-sample until we have n_scenarios valid scenarios
         - Return list of valid ScenarioComponents

    2. **ScenarioGenerator function (standalone)**:
       - `def generate_scenarios(track_id: str, n_scenarios: int = 1000, ontology_driver: Optional[OntologyDriver] = None, kernel: Optional[KernelLogic] = None) -> List[ScenarioComponents]`:
         - Create OntologyConstraints if ontology_driver provided
         - Create mock CBN using create_mock_cbn()
         - Instantiate SkeletonNarrative with kernel
         - Call generate_scenarios method
         - Return scenarios list

    3. **CBN-conditioned outcome sampling**:
       - In generate_single_scenario, for each driver:
         - Call `cbn.sample_outcomes(n_samples=1, evidence={"caution": regime.n_cautions > 0})`
         - Extract driver-specific outcomes from sampled DataFrame:
           - laps_led = outcomes[f"{driver_id}_laps_led"].iloc[0]
           - fastest_laps = outcomes[f"{driver_id}_fastest_laps"].iloc[0]
           - finish_position = outcomes[f"{driver_id}_finish_position"].iloc[0]
           - incidents = outcomes[f"{driver_id}_incident_prob"].iloc[0] > 0.5
         - Populate DriverOutcome fields from CBN samples

    4. **Kernel post-validation integration**:
       - In generate_scenarios, after generating each scenario:
         - Convert ScenarioComponents to dict format for kernel
         - Call `kernel.validate_dominator_conservation(scenario_dict)` if kernel provided
         - Filter scenarios where ConservationResult.is_valid == True
         - Populate conservation_metadata from ConservationResult

    5. **Feasible-by-design conservation**:
       - Use Dirichlet sampling for laps_led to ensure sum = race_length:
         ```python
         import jax.numpy as jnp
         proportions = jax.random.dirichlet(key, jnp.ones(n_drivers))
         laps_led = (proportions * race_length).astype(int)
         # Handle rounding error
         remainder = race_length - laps_led.sum()
         laps_led = laps_led.at[jnp.argmax(laps_led)].add(remainder)
         ```
       - Apply same approach for fastest_laps (sum ≤ green_flag_laps)
       - NOTE: This is feasible-by-design sampling to make scenarios likely valid, but kernel provides final validation

    6. **Hybrid granularity simulation**:
       - **Fine granularity** (key segments): Cautions, pit cycles, final 20% of race
         - Use detailed CBN sampling for each driver
         - Apply state space transitions lap-by-lap
       - **Coarse granularity** (non-key segments): Green flag runs between events
         - Use latent factor transitions (sample final position directly from CBN)
         - Skip lap-by-lap simulation for efficiency

    7. **JAX integration for performance**:
       - Use `jax.vmap` to vectorize scenario generation
       - Use `jax.jit` to compile validation functions
       - Batch generate scenarios in parallel (100 at a time)

    Import from prior plans:
    - `from packages.axiomatic_sim.src.state_space import RaceState, green_flag_transition, caution_transition, pit_cycle_transition`
    - `from packages.axiomatic_sim.src.cbn import CausalBayesianNetwork`
    - `from packages.axiomatic_sim.src.ontology_constraints import OntologyConstraints`
    - `from packages.axiomatic_sim.src.narrative import RaceFlowRegime, ScenarioComponents, DriverOutcome, ConservationMetadata`

    Import kernel for post-validation:
    - `try: from apps.backend.app.kernel import KernelLogic except ImportError: KernelLogic = None`

    Import JAX for performance:
    - `import jax.numpy as jnp`
    - `import jax.random as random`
    - `from jax import vmap, jit`

    DO NOT: Implement optimization (that's Phase 3). DO NOT: Implement telemetry ingestion (that's Phase 2). DO NOT: Perform internal conservation validation - kernel handles this.
  </action>
  <verify>
    Run `python -c "from packages.axiomatic_sim.src.scenario_generator import SkeletonNarrative, generate_scenarios, create_mock_cbn; print('Scenario generator imports successfully')"` (may have JAX import error if not installed, that's OK for now)
  </verify>
  <done>
    SkeletonNarrative generates scenarios with CBN-conditioned outcomes, create_mock_cbn creates fixed CBN with priors, generate_scenarios produces 1,000+ kernel-validated scenarios, conservation enforced via Dirichlet sampling + kernel post-validation, CBN.sample_outcomes called with evidence
  </done>
</task>

<task type="auto">
  <name>Create integration tests for scenario generation pipeline</name>
  <files>packages/axiomatic-sim/tests/test_scenario_generator.py</files>
  <action>
    Create `packages/axiomatic-sim/tests/test_scenario_generator.py` with integration tests:

    1. **test_scenario_generation_produces_valid_scenarios**:
       - Given: Mock CBN, OntologyConstraints, and KernelLogic
       - When: Generate 100 scenarios
       - Then: All scenarios pass kernel conservation validation (validation_passed=True)

    2. **test_scenario_count_target_met**:
       - Given: Mock CBN, OntologyConstraints, and KernelLogic
       - When: Request 1,000 scenarios
       - Then: Exactly 1,000 valid scenarios returned

    3. **test_laps_led_conservation**:
       - Given: List of scenarios
       - When: Sum laps_led across all drivers
       - Then: Total ≤ race_length for each scenario

    4. **test_fastest_laps_conservation**:
       - Given: List of scenarios
       - When: Sum fastest_laps across all drivers
       - Then: Total ≤ green_flag_laps for each scenario

    5. **test_race_flow_regime_diversity**:
       - Given: 1,000 scenarios
       - When: Examine n_cautions distribution
       - Then: Variance > 0 (not all scenarios have same caution count)

    6. **test_scenario_serialization_roundtrip**:
       - Given: Sample scenario
       - When: Serialize to parquet, deserialize back
       - Then: Deserialized scenario equals original (all fields match)

    7. **test_kernel_post_validation_called**:
       - Given: SkeletonNarrative with mock kernel
       - When: Generate 10 scenarios
       - Then: kernel.validate_dominator_conservation called for each scenario
       - Verify: Mock kernel call count equals 10

    Use pytest fixtures for setup:
    - `@pytest.fixture` for mock CBN (return fixed distributions)
    - `@pytest.fixture` for mock OntologyConstraints (return fixed priors)
    - `@pytest.fixture` for mock KernelLogic (track validate_dominator_conservation calls)

    Mock external dependencies:
    - Mock CausalBayesianNetwork to return deterministic samples
    - Mock OntologyConstraints to return fixed skill/difficulty values
    - Mock KernelLogic to track validation calls and return valid ConservationResult

    Run with: `pytest packages/axiomatic-sim/tests/test_scenario_generator.py -v`

    DO NOT: Test single transitions (covered in test_state_space.py). DO NOT: Test CBN learning (covered in test_ontology_constraints.py).
  </action>
  <verify>
    Run `pytest packages/axiomatic-sim/tests/test_scenario_generator.py -v` and verify all 7 tests pass
  </verify>
  <done>
    All 7 integration tests pass, 1,000 scenarios generated, kernel validation called for each scenario, conservation holds for all scenarios, regime variance is diverse, serialization roundtrip preserves data
  </done>
</task>

</tasks>

<verification>
Run test suite: `pytest packages/axiomatic-sim/tests/test_scenario_generator.py -v`

Integration test: Generate 100 scenarios with kernel validation and verify conservation:
```bash
python -c "
from packages.axiomatic_sim.src.scenario_generator import generate_scenarios
from packages.axiomatic_sim.src.narrative import serialize_scenarios_to_parquet
from apps.backend.app.kernel import KernelLogic

kernel = KernelLogic(field_size=40)
scenarios = generate_scenarios('test_track', n_scenarios=100, kernel=kernel)
print(f'Generated {len(scenarios)} scenarios')

# Verify kernel validated all scenarios
for s in scenarios[:10]:
    assert s.conservation_metadata.validation_passed == True
    assert s.conservation_metadata.total_laps_led <= s.conservation_metadata.green_flag_laps
print('Kernel conservation validated for sample scenarios')

# Test serialization
serialize_scenarios_to_parquet(scenarios, '/tmp/test_scenarios.parquet')
print('Serialization successful')
"
```

Check JAX integration: `python -c "import jax; print(f'JAX version: {jax.__version__}'); print(f'JAX devices: {jax.devices()}')"`
</verification>

<success_criteria>
1. SkeletonNarrative generates 1,000+ valid scenarios per slate
2. All scenarios pass kernel conservation validation (laps_led, fastest_laps conserved)
3. Race-flow regimes vary (caution count, pit strategy, fuel risk)
4. Hybrid granularity used (fine for key segments, coarse for green runs)
5. Parquet serialization works for scenario storage
6. Integration tests validate end-to-end pipeline including kernel post-validation
7. create_mock_cbn creates CBN with fixed priors from ontology
</success_criteria>

<output>
After completion, create `.planning/phases/01-feasible-by-design-nascar-simulation-core/01-03-SUMMARY.md`
</output>
