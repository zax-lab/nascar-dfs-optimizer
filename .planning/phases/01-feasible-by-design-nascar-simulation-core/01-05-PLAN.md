---
phase: 01-feasible-by-design-nascar-simulation-core
plan: 05
type: execute
wave: 5
depends_on: ["01-02"]
files_modified:
  - packages/axiomatic-sim/src/axiomatic_sim/cbn.py
  - packages/axiomatic-sim/tests/test_cbn_sampling.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "CausalBayesianNetwork.sample_outcomes() generates real driver outcomes from learned CPDs"
    - "Forward sampling from CPDs produces conditioned samples (e.g., P(laps_led | skill=high))")
    - "Sampled outcomes respect discrete variable constraints (laps_led >= 0, finish_position 1-40)")
    - "Evidence conditioning works (e.g., caution=True produces different outcome distributions)")
  artifacts:
    - path: "packages/axiomatic-sim/src/axiomatic_sim/cbn.py"
      provides: "CBN forward sampling from learned CPDs using pgmpy inference"
      min_lines: 250
      exports: ["CausalBayesianNetwork.sample_outcomes"]
    - path: "packages/axiomatic-sim/tests/test_cbn_sampling.py"
      provides: "Tests for CBN forward sampling and evidence conditioning"
      min_lines: 120
  key_links:
    - from: "packages/axiomatic-sim/src/axiomatic_sim/cbn.py"
      to: "packages/axiomatic-sim/src/axiomatic_sim/cbn.py"
      via: "sample_outcomes() uses self.model (pgmpy BayesianNetwork) and self.cpds"
      pattern: "self\.model\.get_cpds\("
    - from: "packages/axiomatic-sim/tests/test_cbn_sampling.py"
      to: "packages/axiomatic-sim/src/axiomatic_sim/cbn.py"
      via: "Import CausalBayesianNetwork and test sample_outcomes method"
      pattern: "from.*cbn.*import.*CausalBayesianNetwork"
---

<objective>
Implement forward sampling from learned CBN CPDs to replace placeholder implementation in CausalBayesianNetwork.sample_outcomes().

Purpose: Enable real driver outcome generation conditioned on causal relationships (e.g., high-skill drivers lead more laps, aggressive drivers have more incidents). This unblocks scenario generation from using CBN-conditioned outcomes instead of simplified logic.

Output: Working forward sampling implementation using pgmpy VariableElimination inference, tests verifying conditioned sampling produces valid distributions
</objective>

<execution_context>
@/Users/zax/.claude/get-shit-done/workflows/execute-plan.md
@/Users/zax/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-feasible-by-design-nascar-simulation-core/01-CONTEXT.md
@.planning/phases/01-feasible-by-design-nascar-simulation-core/01-RESEARCH.md
@.planning/phases/01-feasible-by-design-nascar-simulation-core/01-feasible-by-design-nascar-simulation-core-VERIFICATION.md
@/Users/zax/Desktop/nascar-model copy 2/.planning/phases/01-feasible-by-design-nascar-simulation-core/01-02-PLAN.md
@/Users/zax/Desktop/nascar-model copy 2/packages/axiomatic-sim/src/axiomatic_sim/cbn.py

# Gap being closed:
Gap 1 from verification report: "CausalBayesianNetwork.sample_outcomes() returns placeholder hardcoded values instead of sampling from learned CPDs"

Lines 188-211 in cbn.py contain TODO comment and placeholder implementation returning fixed values (skill=0.5, laps_led=0, fastest_laps=0).

# Research decisions from 01-RESEARCH.md:
- pgmpy VariableElimination for exact inference
- Forward sampling by sampling from learned CPDs topologically
- Evidence conditioning via VariableElimination.query()
</context>

<tasks>

<task type="auto">
  <name>Implement forward sampling from learned CBN CPDs</name>
  <files>packages/axiomatic-sim/src/axiomatic_sim/cbn.py</files>
  <action>
    Replace the placeholder implementation in `CausalBayesianNetwork.sample_outcomes()` (lines 188-221) with real forward sampling from learned CPDs:

    1. **Topological sort for sampling order**:
       ```python
       # Get topological order of variables (parents before children)
       variables_sorted = list(nx.topological_sort(self.structure))
       ```

    2. **Forward sampling algorithm**:
       For each sample in n_samples:
       - Initialize empty dict for sampled values
       - For each variable in topological order:
         - Get CPD for this variable: `cpd = self.model.get_cpds(variable)`
         - If variable has parents in sampled evidence:
           - Use VariableElimination to query P(variable | evidence)
           - Sample from this conditional distribution
         - If variable has no parents:
           - Sample from prior CPD directly
         - Store sampled value
       - Add complete sample to list

    3. **Evidence conditioning**:
       - If evidence dict provided (e.g., {"caution": True}), merge into sampled values
       - For variables in evidence: skip sampling, use evidence value
       - This ensures P(laps_led | caution=True) samples from conditioned distribution

    4. **Variable-specific sampling**:
       - Continuous variables (skill, aggression): Sample from Gaussian CPDs
       - Discrete counts (laps_led, fastest_laps): Sample from Poisson or Binomial CPDs
       - Categorical (finish_position): Sample from categorical CPD
       - Boolean (incident): Sample from Bernoulli CPD

    5. **Remove placeholder code**:
       - Delete lines 188-211 (placeholder with logger.warning "not yet implemented")
       - Replace with real sampling implementation

    6. **Logging**:
       - Log sampling start: `logger.info(f"Sampling {n_samples} outcomes from CBN with {len(self.structure.nodes())} variables")`
       - Log evidence conditioning if provided
       - Log sampling completion with distribution statistics (mean, std for continuous vars)

    Use pgmpy components:
    - `from pgmpy.inference import VariableElimination`
    - `import networkx as nx`

    DO NOT: Change the method signature (keep n_samples, evidence parameters). DO NOT: Modify other CBN methods (learn_parameters, get_conditional_probability).
  </action>
  <verify>
    Run test: `python -c "
from packages.axiomatic_sim.src.cbn import CausalBayesianNetwork
import pandas as pd

# Create simple CBN structure
import networkx as nx
structure = nx.DiGraph()
structure.add_edge('skill', 'laps_led')
structure.add_edge('skill', 'finish_position')

# Mock CBN (without real CPDs for quick test)
print('CBN module loads, sample_outcomes method exists')
print('Method signature:', CausalBayesianNetwork.sample_outcomes.__annotations__)
"
    `
  </verify>
  <done>
    Placeholder code removed (lines 188-211), forward sampling uses topological order, VariableElimination used for evidence conditioning, samples from learned CPDs not hardcoded values, logging replaced TODO warning
  </done>
</task>

<task type="auto">
  <name>Create tests for CBN forward sampling and evidence conditioning</name>
  <files>packages/axiomatic-sim/tests/test_cbn_sampling.py</files>
  <action>
    Create `packages/axiomatic-sim/tests/test_cbn_sampling.py` with:

    1. **test_forward_sampling_from_cpds**:
       - Given: CBN with learned CPDs (skill → laps_led → finish_position)
       - When: Call sample_outcomes(n_samples=100)
       - Then: All sampled values in valid ranges (laps_led >= 0, finish_position 1-40)
       - And: No hardcoded values (variance > 0 across samples)

    2. **test_evidence_conditioning_changes_distribution**:
       - Given: Same CBN
       - When: Sample with evidence={"skill": 0.9} vs evidence={"skill": 0.1}
       - Then: Mean laps_led higher for high-skill evidence
       - Verify: samples_high_skill["laps_led"].mean() > samples_low_skill["laps_led"].mean()

    3. **test_discrete_variable_constraints**:
       - Given: CBN with discrete variables (laps_led, fastest_laps, finish_position)
       - When: Sample 100 outcomes
       - Then:
         - All laps_led >= 0
         - All fastest_laps >= 0
         - All finish_position in [1, 40]
         - Sum laps_led across samples has realistic variance

    4. **test_sampling_respects_causal_structure**:
       - Given: CBN with structure (aggression → incident → dnf_lap)
       - When: Sample with high aggression evidence
       - Then: Higher incident rate than low aggression evidence
       - Verify: P(incident=True | aggression=0.9) > P(incident=True | aggression=0.1)

    5. **test_reproducible_sampling_with_seed**:
       - Given: CBN with fixed random seed
       - When: Sample twice with same seed
       - Then: Identical samples produced
       - Verify: (samples1 == samples2).all().all()

    Use pytest fixtures for CBN setup:
    - `@pytest.fixture` for simple_cbn (2-3 variables, manually specified CPDs)
    - Mock CPDs with pgmpy TabularCPD for deterministic testing

    Use Hypothesis for property-based testing:
    - `@given(st.integers(min_value=10, max_value=1000))` for n_samples
    - Verify properties hold across random sample sizes

    Run with: `pytest packages/axiomatic-sim/tests/test_cbn_sampling.py -v`

    DO NOT: Test structure learning (covered in test_ontology_constraints.py). DO NOT: Test parameter learning (integration, not unit).
  </action>
  <verify>
    Run: `pytest packages/axiomatic-sim/tests/test_cbn_sampling.py -v`
    Verify all 5 tests pass
  </verify>
  <done>
    All 5 tests pass, forward sampling produces valid distributions, evidence conditioning changes outcome distributions as expected, discrete constraints respected, causal structure influences sampling, reproducible with seed
  </done>
</task>

</tasks>

<verification>
Run test suite: `pytest packages/axiomatic-sim/tests/test_cbn_sampling.py -v`

Integration verification: Test that sample_outcomes no longer returns placeholder values:
```bash
python -c "
from packages.axiomatic_sim.src.cbn import CausalBayesianNetwork
import networkx as nx

# Create minimal CBN
structure = nx.DiGraph()
structure.add_edges_from([('skill', 'laps_led'), ('aggression', 'incident')])

# Create mock CBN instance
from packages.axiomatic_sim.src.ontology_constraints import OntologyConstraints
ontology = OntologyConstraints()  # Will use mock driver
cbn = CausalBayesianNetwork(structure, ontology)

# Try sampling (should not return placeholder values)
import pandas as pd
samples = cbn.sample_outcomes(n_samples=10, evidence={'skill': 0.8})

# Verify samples are not all hardcoded zeros
assert samples['laps_led'].var() > 0 or len(samples) == 0, 'Samples have variance (not placeholder)'
print('CBN sampling produces real values, not placeholders')
"
```

Check no TODO warnings in logs: Run sampling and verify "Forward sampling from CPDs not yet implemented" warning does NOT appear
</verification>

<success_criteria>
1. Placeholder code (lines 188-211) replaced with real forward sampling
2. sample_outcomes uses topological sort to sample from learned CPDs
3. VariableElimination used for evidence conditioning
4. All sampled values respect variable constraints (discrete ranges, continuous bounds)
5. Evidence conditioning produces different outcome distributions (verified by tests)
6. No TODO/placeholder warnings in logs
7. Tests verify sampling respects causal structure
</success_criteria>

<output>
After completion, create `.planning/phases/01-feasible-by-design-nascar-simulation-core/01-05-SUMMARY.md`
</output>
